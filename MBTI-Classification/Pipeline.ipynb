{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped a line due to unexpected format:   Naomi Chung's Daydream Art ï¿½ 25 April 2013 A morning glory flower 10AM###68611http://farm9.staticflickr.com/8402/8677841950_e3793c825c.jpg Flickr \n",
      "\n",
      "Skipped a line due to unexpected format:   Naomi Chung's Daydream Art ï¿½ 24 april 2013 the morning glory flowers\"\n",
      "\n",
      "Skipped a line due to unexpected format:  /-ï¿½ï¿½? \u0011\n",
      "\n",
      "Skipped a line due to unexpected format:   My eyes seem to do the same thing too. Different clothes and hair colour always change up how my eye colour looks.   Sent from my SM-G920W8 using Tapatalk###Thankyou!! This photo is filtered so my eye colour looks tweaked.. but they often change blue/grey/green =\n",
      "\n",
      "Skipped a line due to unexpected format:  =\n",
      "\n",
      "Skipped a line due to unexpected format:  ia ju lijepo. Uz to se i lijepo napijea i pomiria sa \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def custom_csv_reader(file_path, encoding='ISO-8859-1'):\n",
    "    # Initialize lists to hold each column's data\n",
    "    types = []\n",
    "    posts = []\n",
    "    \n",
    "    # Open the file and read line by line\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            # Split the line at the first comma\n",
    "            split_line = line.strip().split(',', 1)\n",
    "            if len(split_line) == 2:\n",
    "                mbti_type, post_data = split_line\n",
    "                # Split posts by \"|||\"\n",
    "                split_posts = post_data.split('###')\n",
    "                for post in split_posts:\n",
    "                    if post.strip() and not re.match(r'^\\s*http\\S+\\s*$', post.strip()):  # Skip empty or pure-link posts\n",
    "                        types.append(mbti_type)\n",
    "                        posts.append(post.strip())\n",
    "            else:\n",
    "                print(\"Skipped a line due to unexpected format: \", line)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'type': types,\n",
    "        'posts': posts\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = custom_csv_reader('mbti_1.csv')\n",
    "\n",
    "\n",
    "df = df[df['type'].str.match(r'^[EI][SN][TF][JP]$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>\"'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412173</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412174</th>\n",
       "      <td>INFP</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412175</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412176</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412177</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts\n",
       "1       INFJ       \"'http://www.youtube.com/watch?v=qsXHcwe3krw\n",
       "2       INFJ  enfp and intj moments  https://www.youtube.com...\n",
       "3       INFJ  What has been the most life-changing experienc...\n",
       "4       INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...\n",
       "5       INFJ               May the PerC Experience immerse you.\n",
       "...      ...                                                ...\n",
       "412173  INFP  I was going to close my facebook a few months ...\n",
       "412174  INFP  30 Seconds to Mars - All of my collections. It...\n",
       "412175  INFP  I have seen it, and i agree. I did actually th...\n",
       "412176  INFP  Ok so i have just watched Underworld 4 (Awaken...\n",
       "412177  INFP  I would never want to turn off my emotions. so...\n",
       "\n",
       "[411479 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['posts'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['posts'])\n",
    "data = pad_sequences(sequences, maxlen=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411479,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LabelEncoder = LabelEncoder()\n",
    "labels = df['type'].values\n",
    "labels = LabelEncoder.fit_transform(labels)\n",
    "\n",
    "print(labels.shape)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "class MBTIDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=5000, embedding_dim=64)\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411479,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 32919/32919 [09:11<00:00, 59.74it/s, loss=1.51]\n",
      "Epoch 2/3: 100%|██████████| 32919/32919 [09:30<00:00, 57.75it/s, loss=1.9] \n",
      "Epoch 3/3: 100%|██████████| 32919/32919 [09:50<00:00, 55.79it/s, loss=2.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape at the end of training: (411479,)\n",
      "End of Epoch 3, Average Loss: 2.1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 8230/8230 [00:30<00:00, 266.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Loss: 2.0753893852233887, Accuracy: 0.27987994556236023, Recall: 0.1356334668547586, Precision: 0.33114335641553005, F1 Score: 0.1485429401488319\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 32919/32919 [09:33<00:00, 57.38it/s, loss=2.94]\n",
      "Epoch 2/3: 100%|██████████| 32919/32919 [09:22<00:00, 58.51it/s, loss=3.3] \n",
      "Epoch 3/3: 100%|██████████| 32919/32919 [09:12<00:00, 59.61it/s, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape at the end of training: (411479,)\n",
      "End of Epoch 3, Average Loss: 2.1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 8230/8230 [00:27<00:00, 294.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Loss: 2.106515884399414, Accuracy: 0.279466802760766, Recall: 0.133155581114039, Precision: 0.3330849351254649, F1 Score: 0.1461915081163473\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 32919/32919 [09:21<00:00, 58.59it/s, loss=3.59]\n",
      "Epoch 2/3: 100%|██████████| 32919/32919 [09:30<00:00, 57.66it/s, loss=1.52]\n",
      "Epoch 3/3: 100%|██████████| 32919/32919 [09:17<00:00, 59.08it/s, loss=1.91] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape at the end of training: (411479,)\n",
      "End of Epoch 3, Average Loss: 2.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 8230/8230 [00:29<00:00, 275.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Loss: 1.9079135656356812, Accuracy: 0.2782152230971129, Recall: 0.13917124585354212, Precision: 0.3618244250121998, F1 Score: 0.15643857436147487\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 32919/32919 [09:33<00:00, 57.38it/s, loss=2.38]\n",
      "Epoch 2/3: 100%|██████████| 32919/32919 [09:37<00:00, 57.01it/s, loss=2.9] \n",
      "Epoch 3/3: 100%|██████████| 32919/32919 [09:14<00:00, 59.39it/s, loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape at the end of training: (411479,)\n",
      "End of Epoch 3, Average Loss: 2.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 8230/8230 [00:28<00:00, 290.29it/s]\n",
      "/Users/rithikkumars/miniconda3/envs/kasturi_ml_project/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Loss: 1.8683291673660278, Accuracy: 0.27934529017206183, Recall: 0.1382239648357379, Precision: 0.35967254815950456, F1 Score: 0.1561806273532424\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 32919/32919 [09:19<00:00, 58.81it/s, loss=1.99]\n",
      "Epoch 2/3: 100%|██████████| 32919/32919 [09:20<00:00, 58.72it/s, loss=2.5]  \n",
      "Epoch 3/3: 100%|██████████| 32919/32919 [09:19<00:00, 58.80it/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape at the end of training: (411479,)\n",
      "End of Epoch 3, Average Loss: 2.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 8230/8230 [00:28<00:00, 291.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Loss: 1.9482883214950562, Accuracy: 0.27919071632541465, Recall: 0.1366116787131807, Precision: 0.3411289480754841, F1 Score: 0.14995147846772655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "num_classes = 16\n",
    "num_epochs = 3\n",
    "batch_size = 10\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics_summary = {\n",
    "    'accuracy': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'f1_score': [],\n",
    "    'conf_matrix': []\n",
    "}\n",
    "\n",
    "# Store metrics\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'loss': []\n",
    "}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "    print(f\"Fold {fold+1}\")            \n",
    "    X_train, X_test = None, None\n",
    "    y_train, y_test = None, None\n",
    "    # Split the data\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train = labels[train_index]\n",
    "    y_test = labels[test_index]\n",
    "    # Create datasets\n",
    "    train_dataset = MBTIDataset(X_train, y_train)\n",
    "    test_dataset = MBTIDataset(X_test, y_test)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = LSTMModel(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=True)\n",
    "        for inputs, batch_labels in progress_bar:\n",
    "            #inputs, batch_labels = inputs.to(device), batch_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    average_epoch_loss = epoch_loss / len(train_loader)\n",
    "    print(f'labels shape at the end of training: {labels.shape}')\n",
    "    print(f'End of Epoch {epoch + 1}, Average Loss: {average_epoch_loss:.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    labels2 = torch.tensor(labels, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc='Evaluation', leave=True)\n",
    "        for inputs, labels2 in progress_bar:\n",
    "            #inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            y_true.extend(labels2.tolist())\n",
    "\n",
    "            #y_pred.extend(predicted.cpu().numpy())\n",
    "            #y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    metrics_summary['accuracy'].append(acc)\n",
    "    metrics_summary['recall'].append(rec)\n",
    "    metrics_summary['precision'].append(prec)\n",
    "    metrics_summary['f1_score'].append(f1)\n",
    "    metrics_summary['conf_matrix'].append(conf_mat)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Loss: {loss.item()}, Accuracy: {acc}, Recall: {rec}, Precision: {prec}, F1 Score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics Across Folds:\n",
      "Average accuracy: 0.27921959558354315\n",
      "Average recall: 0.13655918747425166\n",
      "Average precision: 0.34537084255763667\n",
      "Average f1_score: 0.15146102568952458\n",
      "Average conf_matrix:\n",
      "[[1.38200e+02 4.02000e+01 7.00000e+00 1.34000e+01 2.60000e+00 2.00000e-01\n",
      "  2.00000e-01 1.20000e+00 1.81000e+02 1.07540e+03 8.22000e+01 2.50400e+02\n",
      "  3.00000e+00 3.80000e+00 7.20000e+00 8.80000e+00]\n",
      " [2.56000e+01 7.16200e+02 2.22000e+01 1.25200e+02 6.40000e+00 1.00000e+00\n",
      "  1.40000e+00 8.00000e+00 4.87200e+02 3.68300e+03 3.39000e+02 9.18800e+02\n",
      "  1.14000e+01 1.98000e+01 3.18000e+01 3.40000e+01]\n",
      " [1.08000e+01 3.02000e+01 1.48600e+02 5.48000e+01 2.40000e+00 2.00000e-01\n",
      "  1.00000e+00 5.00000e+00 1.58800e+02 9.75200e+02 2.17800e+02 5.64600e+02\n",
      "  5.20000e+00 1.02000e+01 7.00000e+00 1.26000e+01]\n",
      " [1.24000e+01 1.14600e+02 3.18000e+01 6.77200e+02 4.20000e+00 8.00000e-01\n",
      "  2.00000e+00 1.54000e+01 4.62400e+02 3.02240e+03 4.90400e+02 1.69760e+03\n",
      "  2.06000e+01 2.58000e+01 2.40000e+01 2.56000e+01]\n",
      " [2.80000e+00 7.00000e+00 1.20000e+00 9.80000e+00 2.52000e+01 0.00000e+00\n",
      "  8.00000e-01 2.00000e-01 3.90000e+01 2.05600e+02 1.80000e+01 7.82000e+01\n",
      "  4.60000e+00 5.60000e+00 8.00000e-01 1.00000e+00]\n",
      " [1.00000e+00 1.72000e+01 3.80000e+00 1.24000e+01 6.00000e-01 1.40000e+00\n",
      "  4.00000e-01 2.80000e+00 3.54000e+01 2.28200e+02 3.76000e+01 8.16000e+01\n",
      "  1.20000e+00 5.60000e+00 8.00000e-01 2.20000e+00]\n",
      " [6.00000e-01 7.60000e+00 6.60000e+00 9.00000e+00 4.00000e-01 0.00000e+00\n",
      "  5.80000e+00 1.60000e+00 3.30000e+01 1.92400e+02 3.06000e+01 8.10000e+01\n",
      "  6.00000e-01 2.40000e+00 3.40000e+00 2.40000e+00]\n",
      " [2.40000e+00 1.52000e+01 5.80000e+00 3.00000e+01 1.80000e+00 0.00000e+00\n",
      "  0.00000e+00 5.04000e+01 7.42000e+01 4.04600e+02 6.08000e+01 1.78400e+02\n",
      "  4.00000e+00 4.60000e+00 6.40000e+00 1.12000e+01]\n",
      " [4.40000e+01 1.86000e+02 2.90000e+01 1.90800e+02 8.00000e+00 4.00000e-01\n",
      "  2.80000e+00 1.88000e+01 2.30120e+03 7.95360e+03 7.45400e+02 2.35000e+03\n",
      "  2.98000e+01 4.52000e+01 3.32000e+01 4.52000e+01]\n",
      " [4.86000e+01 2.16600e+02 3.96000e+01 1.50200e+02 9.40000e+00 8.00000e-01\n",
      "  2.60000e+00 1.24000e+01 1.09280e+03 1.20734e+04 7.64000e+02 2.82280e+03\n",
      "  2.62000e+01 5.72000e+01 4.08000e+01 4.70000e+01]\n",
      " [1.50000e+01 1.28600e+02 3.62000e+01 1.34000e+02 7.20000e+00 6.00000e-01\n",
      "  1.40000e+00 1.06000e+01 6.89800e+02 4.62820e+03 1.71100e+03 2.77040e+03\n",
      "  1.98000e+01 2.30000e+01 3.90000e+01 3.44000e+01]\n",
      " [1.86000e+01 9.24000e+01 3.68000e+01 1.84000e+02 1.18000e+01 8.00000e-01\n",
      "  2.20000e+00 8.80000e+00 6.76600e+02 5.74220e+03 9.50600e+02 4.45380e+03\n",
      "  2.06000e+01 2.46000e+01 3.38000e+01 4.64000e+01]\n",
      " [4.80000e+00 2.02000e+01 5.20000e+00 1.88000e+01 1.60000e+00 0.00000e+00\n",
      "  6.00000e-01 2.00000e+00 1.25000e+02 9.04000e+02 7.64000e+01 2.60000e+02\n",
      "  1.27600e+02 1.18000e+01 1.50000e+01 8.20000e+00]\n",
      " [5.60000e+00 4.84000e+01 9.40000e+00 3.08000e+01 3.80000e+00 1.00000e+00\n",
      "  4.00000e-01 3.80000e+00 1.76800e+02 1.51520e+03 1.14800e+02 3.86800e+02\n",
      "  1.24000e+01 1.67800e+02 1.02000e+01 1.74000e+01]\n",
      " [2.60000e+00 2.74000e+01 3.20000e+00 1.60000e+01 3.80000e+00 2.00000e-01\n",
      "  2.00000e-01 2.00000e+00 1.30600e+02 9.96400e+02 1.45400e+02 4.18200e+02\n",
      "  8.40000e+00 6.40000e+00 1.57800e+02 9.40000e+00]\n",
      " [5.40000e+00 3.42000e+01 6.80000e+00 4.22000e+01 1.80000e+00 2.00000e-01\n",
      "  1.20000e+00 9.60000e+00 2.01800e+02 1.59460e+03 2.17400e+02 8.36600e+02\n",
      "  6.00000e+00 1.36000e+01 1.00000e+01 2.23000e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Metrics Across Folds:\")\n",
    "for key in metrics_summary:\n",
    "    if key == 'conf_matrix':\n",
    "        print(f\"Average {key}:\")\n",
    "        print(np.mean(np.array(metrics_summary[key]), axis=0))\n",
    "    else:\n",
    "        print(f\"Average {key}: {np.mean(metrics_summary[key])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (411479, 128)\n",
      "labels shape: (411479,)\n",
      "<class 'numpy.ndarray'>\n",
      "predicted shape: torch.Size([5])\n",
      "batch_labels shape: torch.Size([4])\n",
      "outputs shape: torch.Size([5, 16])\n"
     ]
    }
   ],
   "source": [
    "print(f'data shape: {data.shape}')\n",
    "print(f'labels shape: {labels.shape}')\n",
    "print(type(labels))\n",
    "print(f'predicted shape: {predicted.shape}')\n",
    "print(f'batch_labels shape: {batch_labels.shape}')\n",
    "print(f'outputs shape: {outputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (329184, 128)\n",
      "y_train shape: (329184,)\n",
      "X_test shape: (82295, 128)\n",
      "y_test shape: (82295,)\n",
      "y_true shape: 82295\n",
      "y_pred shape: 82295\n",
      "Data type of X_train: int32\n",
      "Data type of y_train: int64\n",
      "Label type (should be tensor): <class 'numpy.int64'>\n",
      "Max train_index: 411478, Max test_index: 411473, labels length: 411479\n",
      "train_index type: <class 'numpy.ndarray'>, test_index type: <class 'numpy.ndarray'>, labels type: <class 'numpy.ndarray'>\n",
      "data shape: (411479, 128)\n",
      "labels shape: (411479,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_true shape:\", len(y_true))\n",
    "print(\"y_pred shape:\", len(y_pred))\n",
    "print(\"Data type of X_train:\", X_train.dtype)\n",
    "print(\"Data type of y_train:\", y_train.dtype)\n",
    "\n",
    "# Assuming use of nn.CrossEntropyLoss\n",
    "if isinstance(y_train[0], torch.Tensor):\n",
    "    print(\"Label tensor type:\", y_train[0].dtype)\n",
    "else:\n",
    "    print(\"Label type (should be tensor):\", type(y_train[0]))\n",
    "print(f'Max train_index: {train_index.max()}, Max test_index: {test_index.max()}, labels length: {len(labels)}')\n",
    "print(f'train_index type: {type(train_index)}, test_index type: {type(test_index)}, labels type: {type(labels)}')\n",
    "print(f'data shape: {data.shape}')\n",
    "print(f'labels shape: {labels.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
